
# TODO list:
 x spawn new objeects in front of the camera
 x real time update, auto rendering with low quality profile, no texture cleanup at the beginning of the frame
 x app state serialization (camera, renderer, world, materials) to json, each json as a scene file
 x material unique id instead of pointer (better for serialization)
 - list of materials, add, edit, delete operations
 - proper texture material
 x persistence for materials, json again
 x hittables abstract
 x emitter with side selection

 x ray tracing in one weekend part 3
 x names refactor in hittable_pdf
 x remove isotropic material
 x weight in pdf mixer as a slider in ui
 x fix or remove allow emissive
 - measure variance when sampling pixel, variance output. can this denoise?
 x hitable should be abstract
 x graphics bug, incomplete stripes

 - transition to dx12
 - DXR tutorials and integration
 x new GPU

# Scene ideas:
 - light bend by a sphere, focus in a spot
 - light bend by a prism (to implement: index of refraction depends on the wave length(color))
 - green light focused by sphere is mixed with red light focused by a sphere, both produce yellow
 - light reflected of a diffuse object seen on a different object
 - reflections of an object that is not on the screen
 - reflections of all above in a bigger mirror
 - global illumination
 - glass growing and focusing light in a point
 - glass pendulum throwing a light beam at objects
 - off screen source of light
 - changing glass ir, camera alpha, metal fuzz etc.
 - transition between perspective and orthographic views, done with camera alpha and glass ball as a lense
 - different rays counts for different screen parts
 - refreshing only those parts that changed (low ray count prepass, high ray count pass)
 - scale all vectors until you get out of floating point precision
 - grid of square glass tiles surface/texture behind it, lots of caustics
 - rotating split screen dynamically creating one screen
 
 # Optim ideas:
 - Use depth field, trace pixels close to the camera, first.
 - Probe scene with low resolution or even ray cast, calculate the difference from previous scene. Next frame renders only the diff areas.
 - Anti Aliasing done at the ray level - do we need the same amount for each part of the scene? (dark areas less?)

# Problems with imgui (immediate UI paradigm):
 - Input widget setting new value every character instead of when pressed enter or focus left
 - No panels nesting, drag and drop, snapping to window
 - Minimal input validation, post edit actions

# Dictionary:
 - specular, specularly - calculated based on angle of incidence, surface reflecting rays in one direction (mirrrors, metal etc.)
 - diffuse, diffusely - calculater based on the surface and angle of incidence, reflecting rays in multiple directions
 - emissive - calculated based on emission
 https://www.computerhope.com/jargon/d/diffuse-reflection.htm
 https://en.wikipedia.org/wiki/Diffuse_reflection#/media/File:Lambert2.gif
 - lambertian - ideal diffuse reflection (matte), brightness of the surface to the observer is ideal no matter the angle. Luminance is isotropic.
 https://en.wikipedia.org/wiki/Lambertian_reflectance
 - lambert's cosine law / cosine emission law - luminous intensity observed from an ideal diffusely reflecting surface is directly proportional to the cosine of the angle θ between the direction of the incident light and the surface normal
 https://en.wikipedia.org/wiki/Lambert%27s_cosine_law
 - luminance - measure of luminous intensity per unit area of light travelling in a given direction. The amount of light that passes through, is emitted from or reflected from an area.
 https://en.wikipedia.org/wiki/Luminance
 - isotrophy - uniformity in all directions
 https://en.wikipedia.org/wiki/Isotropy

 - radiance - power emitted/reflected by a surface per unit solid angle, per unit of a projected area. The amount of light incoming to a point from a single direction.
 - radiance vs luminance - radiance is physical measure (RGB), luminance is how humans percieve it, how bright we see something? (scalar)
 - radiance vs luminance - radiance used in radiometry where physical properties are relevant, luminance in photometry where the visual perception is relevant (spectral response)
 - irradiance - irradiance is the amount of light incoming to a certain point from possibly all directions.

 - scatter - spread, distribute

 - albedo
 - attenuation
  
 - zero angle - 0
 - acute/sharp angle - less than 90
 - right angle - 90
 - obtuse/blunt angle - 90-180
 - straight angle - 180
 - reflex angle - 180-360
 - perigon angle - 360
 
 - complementary angle - two angles witha sum of 90
 - suplementary angle - two angles with a sum of 180

 - reciprocal - inversely related

 - normal - perpendicular to a given object
 - perpendicular - when two objects intersect at a right angle
 - orthogonal - when two vectors are perpendicular
 - orthonormal - when two unit vectors are perpendicular
 - collinear - two vectors parallel to each other (same or opposite direction)



 ## Lecture 
 https://www.youtube.com/watch?v=Q1cuuepVNoY&ab_channel=ACMSIGGRAPH
 http://intro-to-dxr.cwyman.org/

 # Tips and tricks
 1. Noisy image?
 - Make sure all lights and colors are within [0,1] range.
 - Make sure bounce rays don't start inside the material (offset them 0.1f off the surface).
 - nan and inf can burn the whole pixel, assert with isfinite() very often.

 # Raytracing history:

 1. Whitted 1980 (shiny stuff)
 - specular reflections and refractions
 - perfect surfaces
 - hard shadows, shadow rays to point lights
 - no random function

 2. Cook 1984 (fuzzy stuff, distribution raytracing)
 - reflection rays randomly perturbed off specular direction
 - soft shadows, rays to random point on the light area
 - perfect surfaces
 - more than one ray per pixel

 3. Kajiya 1986 (path tracing)
 - diffuse surfaces (rand diffuse bounces)
 - a lot of rays per pixel
 - huge demand on denoising


 # Raytracing vs rasterization
 
 Raytracing - stream pixels to triagle buffer to see what triangles cover them
 Rasterization - stream triangles to pixel buffer to see what pixels they cover

 Duals of each other. Computantionally quite diferent. 

 Fundamental question:
 Raytracing - What is visible along this ray?
 Rasterization - What pixels does geometry cover?
 
 Key operation:
 Raytracing - Ray-triangle intersection
 Rasterization - Test if pixel is inside triangle.
 
 How streaming works:
 Raytracing - Stream rays (each tests intersections)
 Rasterization - Stream triangles (each tests pixels)
 
 Ineficiencies:
 Raytracing - Test many intersections per ray.
 Rasterization - Shade many tris per pixel (overdraw)
 
 Acceleration structure:
 Raytracing - Bounding Volume Hierarchies
 Rasterization - Z-buffering (hierarchical)
 
 Drawbacks:
 Raytracing - Traverses memory incoherently
 Rasterization - Oncoherent queries difficult to make
 

 # Bounding Volume Hierarchy
 for N triangles
 Building   O(N log N)
 Updating   O(N)
 Traversing O(log N)
